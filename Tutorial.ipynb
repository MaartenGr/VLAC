{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectors of Locally Aggregated Concepts (VLAC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a name=\"table\">Table of Contents</a>  **\n",
    " \n",
    "1. [Loading Packages](#packages)\n",
    "    \n",
    "2. [Prepare Data](#prepare)\n",
    "\n",
    "3. [Train Model and Transform Features](#train) \n",
    "\n",
    "4. [Transform Features](#transform)\n",
    "\n",
    "5. [Feature Quality](#quality) \n",
    "\n",
    "    5.1 [TF-IDF](#tfidf)\n",
    "    \n",
    "    5.2 [VLAC](#vlac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"packages\">Loading Packages</a> \n",
    "[Back to Table of Contents](#table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vlac import VLAC\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "\n",
    "def balanced_accuracy_score(y_true, y_pred, sample_weight=None,\n",
    "                            adjusted=False):\n",
    "    \"\"\"Compute the balanced accuracy\n",
    "    The balanced accuracy in binary and multiclass classification problems to\n",
    "    deal with imbalanced datasets. It is defined as the average of recall\n",
    "    obtained on each class.\n",
    "    The best value is 1 and the worst value is 0 when ``adjusted=False``.\n",
    "    Read more in the :ref:`User Guide <balanced_accuracy_score>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : 1d array-like\n",
    "        Ground truth (correct) target values.\n",
    "    y_pred : 1d array-like\n",
    "        Estimated targets as returned by a classifier.\n",
    "    sample_weight : array-like of shape = [n_samples], optional\n",
    "        Sample weights.\n",
    "    adjusted : bool, default=False\n",
    "        When true, the result is adjusted for chance, so that random\n",
    "        performance would score 0, and perfect performance scores 1.\n",
    "    Returns\n",
    "    -------\n",
    "    balanced_accuracy : float\n",
    "    See also\n",
    "    --------\n",
    "    recall_score, roc_auc_score\n",
    "    Notes\n",
    "    -----\n",
    "    Some literature promotes alternative definitions of balanced accuracy. Our\n",
    "    definition is equivalent to :func:`accuracy_score` with class-balanced\n",
    "    sample weights, and shares desirable properties with the binary case.\n",
    "    See the :ref:`User Guide <balanced_accuracy_score>`.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Brodersen, K.H.; Ong, C.S.; Stephan, K.E.; Buhmann, J.M. (2010).\n",
    "           The balanced accuracy and its posterior distribution.\n",
    "           Proceedings of the 20th International Conference on Pattern\n",
    "           Recognition, 3121-24.\n",
    "    .. [2] John. D. Kelleher, Brian Mac Namee, Aoife D'Arcy, (2015).\n",
    "           `Fundamentals of Machine Learning for Predictive Data Analytics:\n",
    "           Algorithms, Worked Examples, and Case Studies\n",
    "           <https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics>`_.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.metrics import balanced_accuracy_score\n",
    "    >>> y_true = [0, 1, 0, 0, 1, 0]\n",
    "    >>> y_pred = [0, 1, 0, 0, 0, 1]\n",
    "    >>> balanced_accuracy_score(y_true, y_pred)\n",
    "    0.625\n",
    "    \"\"\"\n",
    "    C = confusion_matrix(y_true, y_pred, sample_weight=sample_weight)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        per_class = np.diag(C) / C.sum(axis=1)\n",
    "    if np.any(np.isnan(per_class)):\n",
    "        warnings.warn('y_pred contains classes not in y_true')\n",
    "        per_class = per_class[~np.isnan(per_class)]\n",
    "    score = np.mean(per_class)\n",
    "    if adjusted:\n",
    "        n_classes = len(per_class)\n",
    "        chance = 1 / n_classes\n",
    "        score -= chance\n",
    "        score /= 1 - chance\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"prepare\">Prepare Data</a> \n",
    "[Back to Table of Contents](#table)\n",
    "\n",
    "In order to prepare the data one must load the corresponding word embeddings either through Gensim or as a simple dictionary (word: vector). It is advised to load only the word embeddings that can be found within the collection of documents as clustering a large number of concepts might be computationally difficult. \n",
    "\n",
    "The collection of documents should be represented as a list of strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = word2vec.KeyedVectors.load_word2vec_format('PATH')\n",
    "with open('Data/r8_glove_1f.pickle', 'rb') as handle:\n",
    "    model = pickle.load(handle)\n",
    "    \n",
    "with open('Data/r8_docs.txt', \"r\") as f:\n",
    "    docs = f.readlines()\n",
    "    \n",
    "with open('Data/r8_labels.txt') as f:\n",
    "    labels=[line for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"train\">Train Model & Transform Features</a> \n",
    "[Back to Table of Contents](#table)  \n",
    "The model can be trained using the .fit_transform() procedure. It should be noted that if you use a FastText model, it is advised to set oov to True as it will create word embeddings for out-of-vocabulary words when applying the VLAC procedure (thus, after clustering word embeddings). \n",
    "\n",
    "Note: It is advised to save the resulting kmeans model as that will allow you to quickly transform new documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlac_model = VLAC(documents=docs, model=model, oov=False)\n",
    "vlac_features, kmeans = vlac_model.fit_transform(num_concepts=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"transform\">Transform Features</a> \n",
    "[Back to Table of Contents](#table)  \n",
    "After having trained the kmeans model, you can use that to quickly transform the features without needing to cluster the embeddings again.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlac_model = VLAC(documents=train_docs, model=model_w2v, oov=False)\n",
    "vlac_features = vlac_model.transform(kmeans=kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"quality\">Feature Quality</a> \n",
    "[Back to Table of Contents](#table)    \n",
    "To test the quality of features one can use them for the classification of documents. Below is an example of how I did the classification. Due to some imbalance in the data balanced accuracy was used as an objective measure. Moreover, 10-fold cross validation was applied combined with LinearSVC as textual documents are typically linearly seperable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"tfidf\">TF-IDF</a> \n",
    "[Back to Table of Contents](#table)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9207233411148211"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_counts = CountVectorizer().fit_transform(docs)\n",
    "X_tfidf = TfidfTransformer().fit_transform(X_counts)\n",
    "accuracy = make_scorer(balanced_accuracy_score)\n",
    "cv_svc = cross_val_score(LinearSVC(random_state=42), X_train_tfidf, labels, cv=10, verbose=0, \n",
    "                         scoring=accuracy)\n",
    "np.mean(cv_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"vlac\">VLAC</a> \n",
    "[Back to Table of Contents](#table)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9290098396883734"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = make_scorer(balanced_accuracy_score)\n",
    "cv_svc = cross_val_score(LinearSVC(random_state=42), vlac_features, labels, cv=10, verbose=0, \n",
    "                         scoring=accuracy)\n",
    "np.mean(cv_svc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
